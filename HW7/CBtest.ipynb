{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CBtest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1e1lssl89EOGlRWMEeRj9LhKwWA22Egdr",
      "authorship_tag": "ABX9TyOGvOR9lDDB07XWOfbtmuLG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GA239/DS_course/blob/master/HW7/CBtest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AknlHA1xNEj0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8467d70f-d20b-4d66-bd41-8b0d1e01c691"
      },
      "source": [
        "!python -V"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_yX6gKBOOXG",
        "colab_type": "text"
      },
      "source": [
        "! cat drive/\"My Drive\"/asd.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IPDqXhPXmw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from IPython.display import Image\n",
        "# try:\n",
        "#   filename = take_photo()\n",
        "#   print('Saved to {}'.format(filename))\n",
        "  \n",
        "#   # Show the image which was just taken.\n",
        "#   display(Image(filename))\n",
        "# except Exception as err:\n",
        "#   # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "#   # grant the page permission to access it.\n",
        "#   print(str(err))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swdM1zrrOPRm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "8b4b3a03-1e9d-4d92-8835-42c5eba09abb"
      },
      "source": [
        "! pip install tensorflow-gpu"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/bf/c28971266ca854a64f4b26f07c4112ddd61f30b4d1f18108b954a746f8ea/tensorflow_gpu-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2MB 30kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.2.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.29.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.34.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-gpu) (47.3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.6.0.post3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.2.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.17.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2020.4.5.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (4.1.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.4.8)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0rW5FmRO6XP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61d5bd97-1fff-42db-9c53-c6a414641d22"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "tf.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_6uwUidPb03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-FHkb_PPx7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for k in uploaded:\n",
        "#   print(k)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnnamlgtP-LF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# files.download('asd.txt')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJDy85yDQQod",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "750991b6-a918-40ea-adc9-e5dfed3021d1"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAJY0dh75Lps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.device('/gpu:0'): \n",
        "  w = tf.Variable(tf.random.normal([3, 2], mean=0.0, stddev=0.4), name='weights') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5hIr3MhY0Vg",
        "colab_type": "text"
      },
      "source": [
        "create variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7db-irIw4TxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = tf.Variable(tf.random.normal([3, 2], mean=0.0, stddev=0.4), name='weights') \n",
        "b = tf.Variable(tf.zeros([2]), name='biases')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyKTpxtM58Gs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2 = tf.Variable(w.read_value(), name='w2') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yav_CCvI4vvi",
        "colab_type": "text"
      },
      "source": [
        "Save/Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h32TF2K7PDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add ops to save and restore all the variables.\n",
        "DRIVE = '/content/drive/My Drive'\n",
        "checkpoint_directory = os.path.join(DRIVE, 'training_checkpoints')\n",
        "checkpoint_prefix = os.path.join(checkpoint_directory, 'ckpt')\n",
        "\n",
        "def save(args, kwargs):\n",
        "  checkpoint = tf.train.Checkpoint(**kwargs)\n",
        "  checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "def load(args, kwargs):\n",
        "  checkpoint = tf.train.Checkpoint(**kwargs)\n",
        "  check_dir = tf.train.latest_checkpoint(checkpoint_directory)\n",
        "  checkpoint.restore(check_dir).assert_consumed()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6lP96zrE8fH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1dad3d55-0552-4167-be48-71a6ae8e8401"
      },
      "source": [
        "x = tf.Variable(tf.zeros(shape=(1)), tf.float32) \n",
        "y = tf.Variable(tf.zeros(shape=(1)), tf.float32) \n",
        "\n",
        "@tf.function\n",
        "def forward(x, y):\n",
        "  return x * y\n",
        "\n",
        "\n",
        "print(forward(2, 3))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(6, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wCVqAWwPA3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = tf.Variable(tf.random.normal([10, 100], mean=0.0, stddev=0.4), name='matrix') \n",
        "v = tf.Variable(tf.random.normal([100], mean=0.0, stddev=0.4), name='vector') \n",
        "m + v; "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpNL6xzngsqE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86a4513e-3f1a-4905-df40-dece8609eb2c"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "n_samples, batch_size, num_steps = 1000, 100, 20000 \n",
        "X_data = np.random.uniform(1, 10, (n_samples, 1)).astype(np.float32) \n",
        "y_data = 2 * X_data + 1 + np.random.normal(0, 2, (n_samples, 1)).astype(np.float32)\n",
        "\n",
        "k = tf.Variable(tf.ones(shape=(1,1)), name=\"W\")\n",
        "b = tf.Variable(tf.zeros(shape=(1)), name=\"b\")\n",
        "\n",
        "display_step = 100 \n",
        "optimizer = tf.optimizers.Adam()\n",
        "\n",
        "@tf.function\n",
        "def lossf(x,y):\n",
        "      return tf.math.reduce_mean((y - (tf.linalg.matmul(x, k) + b)) ** 2)\n",
        "\n",
        "def forward(x, y):\n",
        "  with tf.GradientTape() as t:\n",
        "      loss = lossf(x,y)\n",
        "      gradients = t.gradient(loss, [k, b])\n",
        "      optimizer.apply_gradients(zip(gradients, [k, b]))\n",
        "  return k, b, loss\n",
        "\n",
        "for i in range(num_steps): \n",
        "  indices = np.random.choice(n_samples, batch_size) \n",
        "  X_batch, y_batch = X_data[indices], y_data[indices] \n",
        "  k_val, b_val, lossv = forward(X_batch, y_batch)\n",
        "    \n",
        "  if (i+1) % display_step == 0: \n",
        "    print(f'Эпоха {i+1}:  {lossv}, k={float(k_val)}, b={float(b_val)}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Эпоха 100:  37.97753143310547, k=1.0978363752365112, b=0.09801295399665833\n",
            "Эпоха 200:  33.10771179199219, k=1.1910544633865356, b=0.19149966537952423\n",
            "Эпоха 300:  27.293560028076172, k=1.2782875299453735, b=0.27926769852638245\n",
            "Эпоха 400:  24.250411987304688, k=1.3607184886932373, b=0.3617456257343292\n",
            "Эпоха 500:  17.163101196289062, k=1.4376417398452759, b=0.4384640157222748\n",
            "Эпоха 600:  12.794303894042969, k=1.5099722146987915, b=0.5104207992553711\n",
            "Эпоха 700:  13.552939414978027, k=1.5766059160232544, b=0.5767673850059509\n",
            "Эпоха 800:  11.013250350952148, k=1.6366535425186157, b=0.636677622795105\n",
            "Эпоха 900:  7.66900634765625, k=1.6908718347549438, b=0.6906057000160217\n",
            "Эпоха 1000:  6.5172929763793945, k=1.73971688747406, b=0.7393205165863037\n",
            "Эпоха 1100:  4.825112342834473, k=1.7840701341629028, b=0.7829559445381165\n",
            "Эпоха 1200:  6.027284145355225, k=1.8221126794815063, b=0.8203513026237488\n",
            "Эпоха 1300:  3.561466693878174, k=1.8549062013626099, b=0.8523939847946167\n",
            "Эпоха 1400:  3.3250765800476074, k=1.883162498474121, b=0.8796334266662598\n",
            "Эпоха 1500:  5.002589225769043, k=1.9078468084335327, b=0.9025570154190063\n",
            "Эпоха 1600:  3.6835827827453613, k=1.928394079208374, b=0.9215406179428101\n",
            "Эпоха 1700:  3.987014055252075, k=1.945311427116394, b=0.9370613694190979\n",
            "Эпоха 1800:  3.4866583347320557, k=1.959247350692749, b=0.949286699295044\n",
            "Эпоха 1900:  3.629903793334961, k=1.9706227779388428, b=0.9591733813285828\n",
            "Эпоха 2000:  3.7051992416381836, k=1.9791908264160156, b=0.9662399291992188\n",
            "Эпоха 2100:  4.451888084411621, k=1.984600305557251, b=0.9686914682388306\n",
            "Эпоха 2200:  2.4707107543945312, k=1.9890567064285278, b=0.9717863202095032\n",
            "Эпоха 2300:  4.369421482086182, k=1.9935089349746704, b=0.9747604727745056\n",
            "Эпоха 2400:  3.533762216567993, k=1.996044635772705, b=0.9752984046936035\n",
            "Эпоха 2500:  4.02145528793335, k=1.9993056058883667, b=0.9754379391670227\n",
            "Эпоха 2600:  3.9845480918884277, k=2.000171184539795, b=0.9748831391334534\n",
            "Эпоха 2700:  4.252890110015869, k=2.00087308883667, b=0.973308265209198\n",
            "Эпоха 2800:  3.9899985790252686, k=2.002094030380249, b=0.9715108275413513\n",
            "Эпоха 2900:  3.2625174522399902, k=2.0027732849121094, b=0.9688947200775146\n",
            "Эпоха 3000:  3.939849615097046, k=2.00315523147583, b=0.9662405252456665\n",
            "Эпоха 3100:  3.296956777572632, k=2.0031678676605225, b=0.9631454944610596\n",
            "Эпоха 3200:  3.9126410484313965, k=2.0032451152801514, b=0.9591728448867798\n",
            "Эпоха 3300:  3.4295854568481445, k=2.0054848194122314, b=0.9581066966056824\n",
            "Эпоха 3400:  3.343745231628418, k=2.0044960975646973, b=0.953448474407196\n",
            "Эпоха 3500:  3.2571518421173096, k=2.0034735202789307, b=0.9477202296257019\n",
            "Эпоха 3600:  3.1589040756225586, k=2.005847215652466, b=0.9458531141281128\n",
            "Эпоха 3700:  4.408164978027344, k=2.00616455078125, b=0.9412457346916199\n",
            "Эпоха 3800:  3.4324240684509277, k=2.006122589111328, b=0.9375801086425781\n",
            "Эпоха 3900:  4.813194751739502, k=2.006340265274048, b=0.9323409199714661\n",
            "Эпоха 4000:  3.7799594402313232, k=2.006510019302368, b=0.9271761178970337\n",
            "Эпоха 4100:  3.3713815212249756, k=2.0075371265411377, b=0.9235548377037048\n",
            "Эпоха 4200:  3.007255792617798, k=2.0077905654907227, b=0.9207791090011597\n",
            "Эпоха 4300:  4.2393574714660645, k=2.0104281902313232, b=0.9186474084854126\n",
            "Эпоха 4400:  4.312664031982422, k=2.0113000869750977, b=0.913213312625885\n",
            "Эпоха 4500:  5.08271598815918, k=2.011644124984741, b=0.9116594791412354\n",
            "Эпоха 4600:  4.598723888397217, k=2.012810468673706, b=0.9083974957466125\n",
            "Эпоха 4700:  3.2122926712036133, k=2.0107691287994385, b=0.900201678276062\n",
            "Эпоха 4800:  4.826108932495117, k=2.0100550651550293, b=0.8931383490562439\n",
            "Эпоха 4900:  3.5246787071228027, k=2.0101065635681152, b=0.8865097165107727\n",
            "Эпоха 5000:  4.642004013061523, k=2.0150482654571533, b=0.8863585591316223\n",
            "Эпоха 5100:  4.4727067947387695, k=2.015439987182617, b=0.8840624094009399\n",
            "Эпоха 5200:  3.828885555267334, k=2.0174295902252197, b=0.8823925256729126\n",
            "Эпоха 5300:  2.407247543334961, k=2.0133519172668457, b=0.872843325138092\n",
            "Эпоха 5400:  3.5900657176971436, k=2.0177438259124756, b=0.8711207509040833\n",
            "Эпоха 5500:  4.323271751403809, k=2.018528699874878, b=0.864084780216217\n",
            "Эпоха 5600:  3.490447759628296, k=2.016606330871582, b=0.8571028709411621\n",
            "Эпоха 5700:  3.6168928146362305, k=2.026456356048584, b=0.8642902374267578\n",
            "Эпоха 5800:  3.9486031532287598, k=2.0192182064056396, b=0.8534952998161316\n",
            "Эпоха 5900:  4.329201698303223, k=2.020460844039917, b=0.8507768511772156\n",
            "Эпоха 6000:  4.321474075317383, k=2.0140182971954346, b=0.8408822417259216\n",
            "Эпоха 6100:  4.727383136749268, k=2.01942777633667, b=0.8420670032501221\n",
            "Эпоха 6200:  4.04446268081665, k=2.0216968059539795, b=0.8409478664398193\n",
            "Эпоха 6300:  3.7030370235443115, k=2.0150835514068604, b=0.8305982351303101\n",
            "Эпоха 6400:  3.4226932525634766, k=2.0217983722686768, b=0.8297829627990723\n",
            "Эпоха 6500:  3.4761126041412354, k=2.0253024101257324, b=0.8253321051597595\n",
            "Эпоха 6600:  4.0424065589904785, k=2.0238523483276367, b=0.8206501603126526\n",
            "Эпоха 6700:  3.8352954387664795, k=2.0255796909332275, b=0.8209709525108337\n",
            "Эпоха 6800:  4.073930740356445, k=2.0268802642822266, b=0.8218892216682434\n",
            "Эпоха 6900:  3.5326340198516846, k=2.0203166007995605, b=0.8172535300254822\n",
            "Эпоха 7000:  3.4588565826416016, k=2.0289108753204346, b=0.8226400017738342\n",
            "Эпоха 7100:  4.0124711990356445, k=2.019860029220581, b=0.8091056942939758\n",
            "Эпоха 7200:  3.819924831390381, k=2.022507667541504, b=0.8098124265670776\n",
            "Эпоха 7300:  3.552110195159912, k=2.0292365550994873, b=0.81374192237854\n",
            "Эпоха 7400:  3.819439172744751, k=2.0293047428131104, b=0.8091259598731995\n",
            "Эпоха 7500:  3.337334632873535, k=2.0338644981384277, b=0.8045286536216736\n",
            "Эпоха 7600:  3.2608652114868164, k=2.0259432792663574, b=0.791968047618866\n",
            "Эпоха 7700:  3.5022547245025635, k=2.0281894207000732, b=0.7924917936325073\n",
            "Эпоха 7800:  4.470305442810059, k=2.0262134075164795, b=0.7826682925224304\n",
            "Эпоха 7900:  3.889371395111084, k=2.030054807662964, b=0.7851170897483826\n",
            "Эпоха 8000:  4.000729560852051, k=2.031985282897949, b=0.7828032970428467\n",
            "Эпоха 8100:  3.5865540504455566, k=2.02616810798645, b=0.7800388336181641\n",
            "Эпоха 8200:  3.6261539459228516, k=2.027036666870117, b=0.7769416570663452\n",
            "Эпоха 8300:  4.66648006439209, k=2.0285675525665283, b=0.7758815288543701\n",
            "Эпоха 8400:  3.6289093494415283, k=2.033128023147583, b=0.7753499746322632\n",
            "Эпоха 8500:  3.4702789783477783, k=2.0364127159118652, b=0.7752020955085754\n",
            "Эпоха 8600:  3.9831104278564453, k=2.032957077026367, b=0.7721380591392517\n",
            "Эпоха 8700:  3.7741897106170654, k=2.026759386062622, b=0.7682291269302368\n",
            "Эпоха 8800:  4.020497798919678, k=2.0325567722320557, b=0.7681676745414734\n",
            "Эпоха 8900:  4.121206760406494, k=2.04056453704834, b=0.7807817459106445\n",
            "Эпоха 9000:  3.3018457889556885, k=2.0327603816986084, b=0.7710634469985962\n",
            "Эпоха 9100:  4.000399589538574, k=2.0332753658294678, b=0.7713726162910461\n",
            "Эпоха 9200:  3.1577343940734863, k=2.0302770137786865, b=0.7676485776901245\n",
            "Эпоха 9300:  3.941542387008667, k=2.0311007499694824, b=0.7659801244735718\n",
            "Эпоха 9400:  4.485791206359863, k=2.04030179977417, b=0.7707027792930603\n",
            "Эпоха 9500:  3.2688188552856445, k=2.0370676517486572, b=0.7712175846099854\n",
            "Эпоха 9600:  4.698742866516113, k=2.0349268913269043, b=0.7660137414932251\n",
            "Эпоха 9700:  3.594325542449951, k=2.0315017700195312, b=0.7656652927398682\n",
            "Эпоха 9800:  3.8462069034576416, k=2.035613775253296, b=0.7638186812400818\n",
            "Эпоха 9900:  3.4353880882263184, k=2.0330708026885986, b=0.759654700756073\n",
            "Эпоха 10000:  5.531581878662109, k=2.0352487564086914, b=0.7709635496139526\n",
            "Эпоха 10100:  3.8996105194091797, k=2.035515785217285, b=0.7701764106750488\n",
            "Эпоха 10200:  4.304912090301514, k=2.026606321334839, b=0.7579951286315918\n",
            "Эпоха 10300:  4.9060564041137695, k=2.0346765518188477, b=0.7614304423332214\n",
            "Эпоха 10400:  2.961927890777588, k=2.032038688659668, b=0.759939432144165\n",
            "Эпоха 10500:  3.9680521488189697, k=2.027268648147583, b=0.7572442889213562\n",
            "Эпоха 10600:  3.6739919185638428, k=2.039146661758423, b=0.7739110589027405\n",
            "Эпоха 10700:  3.750473737716675, k=2.0315513610839844, b=0.7667479515075684\n",
            "Эпоха 10800:  4.6959710121154785, k=2.0378150939941406, b=0.7716260552406311\n",
            "Эпоха 10900:  4.807843208312988, k=2.0289573669433594, b=0.7633227705955505\n",
            "Эпоха 11000:  3.7891736030578613, k=2.034636974334717, b=0.7727057337760925\n",
            "Эпоха 11100:  4.6393866539001465, k=2.0340287685394287, b=0.7733837962150574\n",
            "Эпоха 11200:  3.4150550365448, k=2.0271894931793213, b=0.7668105959892273\n",
            "Эпоха 11300:  3.2368733882904053, k=2.0356287956237793, b=0.7745003700256348\n",
            "Эпоха 11400:  3.814375877380371, k=2.03139066696167, b=0.7674400806427002\n",
            "Эпоха 11500:  2.717855215072632, k=2.03245210647583, b=0.7693015336990356\n",
            "Эпоха 11600:  4.416506290435791, k=2.0360000133514404, b=0.7742941975593567\n",
            "Эпоха 11700:  3.9542267322540283, k=2.035388708114624, b=0.775300145149231\n",
            "Эпоха 11800:  3.76143217086792, k=2.029956102371216, b=0.7664897441864014\n",
            "Эпоха 11900:  3.5863072872161865, k=2.0328428745269775, b=0.7676161527633667\n",
            "Эпоха 12000:  3.8574001789093018, k=2.029528856277466, b=0.7661746740341187\n",
            "Эпоха 12100:  3.808067560195923, k=2.0310585498809814, b=0.7682810425758362\n",
            "Эпоха 12200:  4.5943989753723145, k=2.029623031616211, b=0.766573429107666\n",
            "Эпоха 12300:  2.8592751026153564, k=2.0296730995178223, b=0.7664238214492798\n",
            "Эпоха 12400:  3.779573678970337, k=2.0276994705200195, b=0.7677522897720337\n",
            "Эпоха 12500:  3.6048078536987305, k=2.0355262756347656, b=0.772577166557312\n",
            "Эпоха 12600:  3.5800364017486572, k=2.030708074569702, b=0.7623575329780579\n",
            "Эпоха 12700:  4.251694679260254, k=2.032919406890869, b=0.7581447958946228\n",
            "Эпоха 12800:  2.9108753204345703, k=2.038255214691162, b=0.7697270512580872\n",
            "Эпоха 12900:  2.838167667388916, k=2.0315096378326416, b=0.7630128264427185\n",
            "Эпоха 13000:  4.131073474884033, k=2.026280641555786, b=0.7600520849227905\n",
            "Эпоха 13100:  3.768733024597168, k=2.0356812477111816, b=0.7672556042671204\n",
            "Эпоха 13200:  4.152719497680664, k=2.0338754653930664, b=0.7625244855880737\n",
            "Эпоха 13300:  3.5527236461639404, k=2.0339019298553467, b=0.7640862464904785\n",
            "Эпоха 13400:  4.55618143081665, k=2.0261194705963135, b=0.754840075969696\n",
            "Эпоха 13500:  3.0178749561309814, k=2.0426461696624756, b=0.770607590675354\n",
            "Эпоха 13600:  3.8138184547424316, k=2.0340943336486816, b=0.7626976370811462\n",
            "Эпоха 13700:  4.48048734664917, k=2.032014846801758, b=0.7617011070251465\n",
            "Эпоха 13800:  3.2754669189453125, k=2.033068895339966, b=0.7674531936645508\n",
            "Эпоха 13900:  4.606143951416016, k=2.03633713722229, b=0.7736449837684631\n",
            "Эпоха 14000:  3.5066328048706055, k=2.0311505794525146, b=0.7684550881385803\n",
            "Эпоха 14100:  3.619154691696167, k=2.031853675842285, b=0.7668753266334534\n",
            "Эпоха 14200:  3.4478044509887695, k=2.04138445854187, b=0.7717208862304688\n",
            "Эпоха 14300:  3.9936535358428955, k=2.038090944290161, b=0.7673496007919312\n",
            "Эпоха 14400:  3.1384048461914062, k=2.0303332805633545, b=0.760246217250824\n",
            "Эпоха 14500:  3.6327948570251465, k=2.031090021133423, b=0.7590146064758301\n",
            "Эпоха 14600:  3.881094455718994, k=2.037926435470581, b=0.7649812698364258\n",
            "Эпоха 14700:  4.992994785308838, k=2.027804374694824, b=0.7585488557815552\n",
            "Эпоха 14800:  3.6426432132720947, k=2.027306079864502, b=0.7510246634483337\n",
            "Эпоха 14900:  3.3347907066345215, k=2.040661096572876, b=0.7640183568000793\n",
            "Эпоха 15000:  3.6511054039001465, k=2.0271098613739014, b=0.7544698715209961\n",
            "Эпоха 15100:  3.298020839691162, k=2.0301921367645264, b=0.7520375847816467\n",
            "Эпоха 15200:  3.563051223754883, k=2.0336289405822754, b=0.7607583403587341\n",
            "Эпоха 15300:  2.4253549575805664, k=2.0332581996917725, b=0.7654181122779846\n",
            "Эпоха 15400:  3.596024513244629, k=2.0359716415405273, b=0.7711582183837891\n",
            "Эпоха 15500:  3.2264480590820312, k=2.0399935245513916, b=0.7730233073234558\n",
            "Эпоха 15600:  3.6439714431762695, k=2.033489465713501, b=0.7688139081001282\n",
            "Эпоха 15700:  3.114135980606079, k=2.028890609741211, b=0.7654967904090881\n",
            "Эпоха 15800:  3.097374200820923, k=2.0321807861328125, b=0.7735875248908997\n",
            "Эпоха 15900:  4.419284820556641, k=2.0333313941955566, b=0.7730570435523987\n",
            "Эпоха 16000:  3.526474952697754, k=2.0336203575134277, b=0.7658039927482605\n",
            "Эпоха 16100:  4.0437541007995605, k=2.0330870151519775, b=0.7691516280174255\n",
            "Эпоха 16200:  4.6735639572143555, k=2.0354416370391846, b=0.7745699882507324\n",
            "Эпоха 16300:  3.506911039352417, k=2.033179759979248, b=0.7686303853988647\n",
            "Эпоха 16400:  3.562467575073242, k=2.0370397567749023, b=0.7677714824676514\n",
            "Эпоха 16500:  3.4449667930603027, k=2.037310838699341, b=0.7680901885032654\n",
            "Эпоха 16600:  4.701887130737305, k=2.037768840789795, b=0.7719582319259644\n",
            "Эпоха 16700:  3.9153380393981934, k=2.033803701400757, b=0.7660248875617981\n",
            "Эпоха 16800:  4.355076789855957, k=2.036907434463501, b=0.7709571123123169\n",
            "Эпоха 16900:  3.4304211139678955, k=2.036409854888916, b=0.7689526677131653\n",
            "Эпоха 17000:  3.78285551071167, k=2.034928798675537, b=0.757911741733551\n",
            "Эпоха 17100:  3.8396735191345215, k=2.035796642303467, b=0.7552679181098938\n",
            "Эпоха 17200:  4.650229454040527, k=2.0380420684814453, b=0.7643043994903564\n",
            "Эпоха 17300:  5.007067680358887, k=2.0354676246643066, b=0.7621495127677917\n",
            "Эпоха 17400:  2.844985246658325, k=2.034290313720703, b=0.76469486951828\n",
            "Эпоха 17500:  3.344633102416992, k=2.0323891639709473, b=0.7659458518028259\n",
            "Эпоха 17600:  3.0867011547088623, k=2.0289266109466553, b=0.7638283967971802\n",
            "Эпоха 17700:  3.550663709640503, k=2.044787883758545, b=0.7774609923362732\n",
            "Эпоха 17800:  3.050537109375, k=2.033982515335083, b=0.7598153352737427\n",
            "Эпоха 17900:  3.1375021934509277, k=2.037328004837036, b=0.7604785561561584\n",
            "Эпоха 18000:  3.4164414405822754, k=2.029808521270752, b=0.7481499314308167\n",
            "Эпоха 18100:  3.815678596496582, k=2.0329225063323975, b=0.7491176128387451\n",
            "Эпоха 18200:  3.564429998397827, k=2.042259693145752, b=0.7599573135375977\n",
            "Эпоха 18300:  2.3385496139526367, k=2.035446882247925, b=0.7531334757804871\n",
            "Эпоха 18400:  3.6387851238250732, k=2.038837432861328, b=0.75716632604599\n",
            "Эпоха 18500:  3.5349178314208984, k=2.0396487712860107, b=0.7643995881080627\n",
            "Эпоха 18600:  4.795227527618408, k=2.029764175415039, b=0.7611545324325562\n",
            "Эпоха 18700:  2.7980074882507324, k=2.0327422618865967, b=0.7699480652809143\n",
            "Эпоха 18800:  4.084855556488037, k=2.037902593612671, b=0.7744430899620056\n",
            "Эпоха 18900:  3.2833542823791504, k=2.037501096725464, b=0.7700269818305969\n",
            "Эпоха 19000:  3.7970361709594727, k=2.0371387004852295, b=0.7674694657325745\n",
            "Эпоха 19100:  2.416980743408203, k=2.0292274951934814, b=0.7540071606636047\n",
            "Эпоха 19200:  3.7262330055236816, k=2.0338222980499268, b=0.7609588503837585\n",
            "Эпоха 19300:  4.651260852813721, k=2.0330166816711426, b=0.7711930274963379\n",
            "Эпоха 19400:  4.646785736083984, k=2.0287351608276367, b=0.7654763460159302\n",
            "Эпоха 19500:  4.70652961730957, k=2.037302255630493, b=0.7708296775817871\n",
            "Эпоха 19600:  3.6595373153686523, k=2.0333125591278076, b=0.7647072076797485\n",
            "Эпоха 19700:  3.8447396755218506, k=2.031416893005371, b=0.7633960247039795\n",
            "Эпоха 19800:  3.879690170288086, k=2.0289902687072754, b=0.7672926783561707\n",
            "Эпоха 19900:  3.7774088382720947, k=2.032318353652954, b=0.7734324336051941\n",
            "Эпоха 20000:  3.6957616806030273, k=2.0380077362060547, b=0.780516505241394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7uI6xG0zsza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential \n",
        "from keras.layers import Input, Dense, Activation \n",
        "import numpy as np"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBv7qYoF9pgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "        \n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8mIoLSs5Uq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logr = Sequential() \n",
        "logr.add(\n",
        "    Dense(1, input_dim=2, activation='sigmoid')) \n",
        "logr.compile(\n",
        "    loss='binary_crossentropy', \n",
        "    optimizer='adam', \n",
        "    metrics=[f1]) "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8u-FRsX5egP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sampler(n, x, y): \n",
        "  return np.random.normal(size=[n, 2]) + [x, y]\n",
        "\n",
        "def sample_data(n=1000, p0=(-1., -1.), p1=(1., 1.)): \n",
        "  zeros, ones = np.zeros((n, 1)), np.ones((n, 1)) \n",
        "  labels = np.vstack([zeros, ones]) \n",
        "  z_sample = sampler(n, x=p0[0], y=p0[1]) \n",
        "  o_sample = sampler(n, x=p1[0], y=p1[1]) \n",
        "  return np.vstack([z_sample, o_sample]), labels\n",
        "\n",
        "X_train, Y_train = sample_data() \n",
        "X_test, Y_test = sample_data(100) "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxJ0zCCu62it",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c0643c9-4d78-4392-95ab-6fa3d3dcc2dc"
      },
      "source": [
        "logr.fit(X_train, Y_train, batch_size=16, nb_epoch=100, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 2000 samples, validate on 200 samples\n",
            "Epoch 1/100\n",
            "2000/2000 [==============================] - 0s 186us/step - loss: 0.9200 - f1: 0.1578 - val_loss: 0.8698 - val_f1: 0.0999\n",
            "Epoch 2/100\n",
            "2000/2000 [==============================] - 0s 152us/step - loss: 0.7835 - f1: 0.3053 - val_loss: 0.7432 - val_f1: 0.2867\n",
            "Epoch 3/100\n",
            "2000/2000 [==============================] - 0s 152us/step - loss: 0.6745 - f1: 0.5775 - val_loss: 0.6439 - val_f1: 0.4373\n",
            "Epoch 4/100\n",
            "2000/2000 [==============================] - 0s 145us/step - loss: 0.5885 - f1: 0.7736 - val_loss: 0.5657 - val_f1: 0.4889\n",
            "Epoch 5/100\n",
            "2000/2000 [==============================] - 0s 147us/step - loss: 0.5210 - f1: 0.8538 - val_loss: 0.5049 - val_f1: 0.5104\n",
            "Epoch 6/100\n",
            "2000/2000 [==============================] - 0s 150us/step - loss: 0.4681 - f1: 0.8790 - val_loss: 0.4566 - val_f1: 0.5171\n",
            "Epoch 7/100\n",
            "2000/2000 [==============================] - 0s 150us/step - loss: 0.4260 - f1: 0.8939 - val_loss: 0.4186 - val_f1: 0.5204\n",
            "Epoch 8/100\n",
            "2000/2000 [==============================] - 0s 145us/step - loss: 0.3923 - f1: 0.8995 - val_loss: 0.3873 - val_f1: 0.5204\n",
            "Epoch 9/100\n",
            "2000/2000 [==============================] - 0s 152us/step - loss: 0.3649 - f1: 0.9035 - val_loss: 0.3620 - val_f1: 0.5204\n",
            "Epoch 10/100\n",
            "2000/2000 [==============================] - 0s 148us/step - loss: 0.3422 - f1: 0.9042 - val_loss: 0.3410 - val_f1: 0.5204\n",
            "Epoch 11/100\n",
            "2000/2000 [==============================] - 0s 141us/step - loss: 0.3234 - f1: 0.9079 - val_loss: 0.3233 - val_f1: 0.5204\n",
            "Epoch 12/100\n",
            "2000/2000 [==============================] - 0s 142us/step - loss: 0.3075 - f1: 0.9095 - val_loss: 0.3083 - val_f1: 0.5204\n",
            "Epoch 13/100\n",
            "2000/2000 [==============================] - 0s 135us/step - loss: 0.2940 - f1: 0.9126 - val_loss: 0.2954 - val_f1: 0.5204\n",
            "Epoch 14/100\n",
            "2000/2000 [==============================] - 0s 143us/step - loss: 0.2823 - f1: 0.9110 - val_loss: 0.2843 - val_f1: 0.5204\n",
            "Epoch 15/100\n",
            "2000/2000 [==============================] - 0s 148us/step - loss: 0.2723 - f1: 0.9147 - val_loss: 0.2747 - val_f1: 0.5204\n",
            "Epoch 16/100\n",
            "2000/2000 [==============================] - 0s 138us/step - loss: 0.2636 - f1: 0.9128 - val_loss: 0.2662 - val_f1: 0.5204\n",
            "Epoch 17/100\n",
            "2000/2000 [==============================] - 0s 147us/step - loss: 0.2559 - f1: 0.9192 - val_loss: 0.2588 - val_f1: 0.5204\n",
            "Epoch 18/100\n",
            "2000/2000 [==============================] - 0s 134us/step - loss: 0.2491 - f1: 0.9196 - val_loss: 0.2522 - val_f1: 0.5204\n",
            "Epoch 19/100\n",
            "2000/2000 [==============================] - 0s 136us/step - loss: 0.2432 - f1: 0.9195 - val_loss: 0.2463 - val_f1: 0.5204\n",
            "Epoch 20/100\n",
            "2000/2000 [==============================] - 0s 145us/step - loss: 0.2379 - f1: 0.9209 - val_loss: 0.2410 - val_f1: 0.5232\n",
            "Epoch 21/100\n",
            "2000/2000 [==============================] - 0s 147us/step - loss: 0.2332 - f1: 0.9196 - val_loss: 0.2364 - val_f1: 0.5232\n",
            "Epoch 22/100\n",
            "2000/2000 [==============================] - 0s 134us/step - loss: 0.2290 - f1: 0.9219 - val_loss: 0.2322 - val_f1: 0.5232\n",
            "Epoch 23/100\n",
            "2000/2000 [==============================] - 0s 136us/step - loss: 0.2253 - f1: 0.9198 - val_loss: 0.2283 - val_f1: 0.5232\n",
            "Epoch 24/100\n",
            "2000/2000 [==============================] - 0s 136us/step - loss: 0.2219 - f1: 0.9223 - val_loss: 0.2248 - val_f1: 0.5232\n",
            "Epoch 25/100\n",
            "2000/2000 [==============================] - 0s 139us/step - loss: 0.2189 - f1: 0.9162 - val_loss: 0.2218 - val_f1: 0.5232\n",
            "Epoch 26/100\n",
            "2000/2000 [==============================] - 0s 138us/step - loss: 0.2162 - f1: 0.9229 - val_loss: 0.2190 - val_f1: 0.5232\n",
            "Epoch 27/100\n",
            "2000/2000 [==============================] - 0s 144us/step - loss: 0.2138 - f1: 0.9176 - val_loss: 0.2163 - val_f1: 0.5232\n",
            "Epoch 28/100\n",
            "2000/2000 [==============================] - 0s 145us/step - loss: 0.2116 - f1: 0.9187 - val_loss: 0.2143 - val_f1: 0.5232\n",
            "Epoch 29/100\n",
            "2000/2000 [==============================] - 0s 136us/step - loss: 0.2096 - f1: 0.9167 - val_loss: 0.2121 - val_f1: 0.5232\n",
            "Epoch 30/100\n",
            "2000/2000 [==============================] - 0s 142us/step - loss: 0.2078 - f1: 0.9198 - val_loss: 0.2102 - val_f1: 0.5232\n",
            "Epoch 31/100\n",
            "2000/2000 [==============================] - 0s 135us/step - loss: 0.2062 - f1: 0.9171 - val_loss: 0.2084 - val_f1: 0.5232\n",
            "Epoch 32/100\n",
            "2000/2000 [==============================] - 0s 140us/step - loss: 0.2047 - f1: 0.9184 - val_loss: 0.2071 - val_f1: 0.5232\n",
            "Epoch 33/100\n",
            "2000/2000 [==============================] - 0s 135us/step - loss: 0.2035 - f1: 0.9151 - val_loss: 0.2056 - val_f1: 0.5232\n",
            "Epoch 34/100\n",
            "2000/2000 [==============================] - 0s 143us/step - loss: 0.2023 - f1: 0.9180 - val_loss: 0.2042 - val_f1: 0.5232\n",
            "Epoch 35/100\n",
            "2000/2000 [==============================] - 0s 137us/step - loss: 0.2012 - f1: 0.9149 - val_loss: 0.2030 - val_f1: 0.5232\n",
            "Epoch 36/100\n",
            "2000/2000 [==============================] - 0s 133us/step - loss: 0.2003 - f1: 0.9157 - val_loss: 0.2019 - val_f1: 0.5232\n",
            "Epoch 37/100\n",
            "2000/2000 [==============================] - 0s 132us/step - loss: 0.1994 - f1: 0.9130 - val_loss: 0.2010 - val_f1: 0.5232\n",
            "Epoch 38/100\n",
            "2000/2000 [==============================] - 0s 143us/step - loss: 0.1987 - f1: 0.9149 - val_loss: 0.2002 - val_f1: 0.5232\n",
            "Epoch 39/100\n",
            "2000/2000 [==============================] - 0s 146us/step - loss: 0.1980 - f1: 0.9174 - val_loss: 0.1994 - val_f1: 0.5232\n",
            "Epoch 40/100\n",
            "2000/2000 [==============================] - 0s 138us/step - loss: 0.1974 - f1: 0.9155 - val_loss: 0.1987 - val_f1: 0.5232\n",
            "Epoch 41/100\n",
            "2000/2000 [==============================] - 0s 142us/step - loss: 0.1968 - f1: 0.9172 - val_loss: 0.1981 - val_f1: 0.5232\n",
            "Epoch 42/100\n",
            "2000/2000 [==============================] - 0s 142us/step - loss: 0.1963 - f1: 0.9145 - val_loss: 0.1977 - val_f1: 0.5232\n",
            "Epoch 43/100\n",
            "2000/2000 [==============================] - 0s 136us/step - loss: 0.1959 - f1: 0.9152 - val_loss: 0.1972 - val_f1: 0.5232\n",
            "Epoch 44/100\n",
            "2000/2000 [==============================] - 0s 136us/step - loss: 0.1955 - f1: 0.9167 - val_loss: 0.1964 - val_f1: 0.5232\n",
            "Epoch 45/100\n",
            "2000/2000 [==============================] - 0s 144us/step - loss: 0.1952 - f1: 0.9155 - val_loss: 0.1961 - val_f1: 0.5232\n",
            "Epoch 46/100\n",
            "2000/2000 [==============================] - 0s 137us/step - loss: 0.1949 - f1: 0.9144 - val_loss: 0.1959 - val_f1: 0.5232\n",
            "Epoch 47/100\n",
            "2000/2000 [==============================] - 0s 134us/step - loss: 0.1946 - f1: 0.9184 - val_loss: 0.1954 - val_f1: 0.5232\n",
            "Epoch 48/100\n",
            "2000/2000 [==============================] - 0s 139us/step - loss: 0.1944 - f1: 0.9185 - val_loss: 0.1951 - val_f1: 0.5232\n",
            "Epoch 49/100\n",
            "2000/2000 [==============================] - 0s 145us/step - loss: 0.1942 - f1: 0.9154 - val_loss: 0.1951 - val_f1: 0.5232\n",
            "Epoch 50/100\n",
            "2000/2000 [==============================] - 0s 139us/step - loss: 0.1940 - f1: 0.9156 - val_loss: 0.1948 - val_f1: 0.5232\n",
            "Epoch 51/100\n",
            "2000/2000 [==============================] - 0s 136us/step - loss: 0.1938 - f1: 0.9152 - val_loss: 0.1945 - val_f1: 0.5232\n",
            "Epoch 52/100\n",
            "2000/2000 [==============================] - 0s 143us/step - loss: 0.1937 - f1: 0.9164 - val_loss: 0.1945 - val_f1: 0.5232\n",
            "Epoch 53/100\n",
            "2000/2000 [==============================] - 0s 138us/step - loss: 0.1936 - f1: 0.9174 - val_loss: 0.1941 - val_f1: 0.5232\n",
            "Epoch 54/100\n",
            "2000/2000 [==============================] - 0s 133us/step - loss: 0.1934 - f1: 0.9139 - val_loss: 0.1941 - val_f1: 0.5232\n",
            "Epoch 55/100\n",
            "2000/2000 [==============================] - 0s 141us/step - loss: 0.1934 - f1: 0.9180 - val_loss: 0.1939 - val_f1: 0.5232\n",
            "Epoch 56/100\n",
            "2000/2000 [==============================] - 0s 140us/step - loss: 0.1933 - f1: 0.9137 - val_loss: 0.1938 - val_f1: 0.5232\n",
            "Epoch 57/100\n",
            "2000/2000 [==============================] - 0s 141us/step - loss: 0.1932 - f1: 0.9146 - val_loss: 0.1938 - val_f1: 0.5232\n",
            "Epoch 58/100\n",
            "2000/2000 [==============================] - 0s 143us/step - loss: 0.1931 - f1: 0.9151 - val_loss: 0.1936 - val_f1: 0.5232\n",
            "Epoch 59/100\n",
            "2000/2000 [==============================] - 0s 137us/step - loss: 0.1931 - f1: 0.9165 - val_loss: 0.1935 - val_f1: 0.5232\n",
            "Epoch 60/100\n",
            "2000/2000 [==============================] - 0s 140us/step - loss: 0.1931 - f1: 0.9145 - val_loss: 0.1936 - val_f1: 0.5232\n",
            "Epoch 61/100\n",
            "2000/2000 [==============================] - 0s 136us/step - loss: 0.1930 - f1: 0.9121 - val_loss: 0.1936 - val_f1: 0.5232\n",
            "Epoch 62/100\n",
            "2000/2000 [==============================] - 0s 133us/step - loss: 0.1929 - f1: 0.9146 - val_loss: 0.1934 - val_f1: 0.5232\n",
            "Epoch 63/100\n",
            "2000/2000 [==============================] - 0s 142us/step - loss: 0.1929 - f1: 0.9171 - val_loss: 0.1932 - val_f1: 0.5232\n",
            "Epoch 64/100\n",
            "2000/2000 [==============================] - 0s 141us/step - loss: 0.1929 - f1: 0.9189 - val_loss: 0.1932 - val_f1: 0.5232\n",
            "Epoch 65/100\n",
            "2000/2000 [==============================] - 0s 135us/step - loss: 0.1929 - f1: 0.9128 - val_loss: 0.1933 - val_f1: 0.5232\n",
            "Epoch 66/100\n",
            "2000/2000 [==============================] - 0s 135us/step - loss: 0.1928 - f1: 0.9181 - val_loss: 0.1933 - val_f1: 0.5232\n",
            "Epoch 67/100\n",
            "2000/2000 [==============================] - 0s 141us/step - loss: 0.1928 - f1: 0.9162 - val_loss: 0.1932 - val_f1: 0.5232\n",
            "Epoch 68/100\n",
            "2000/2000 [==============================] - 0s 140us/step - loss: 0.1928 - f1: 0.9139 - val_loss: 0.1932 - val_f1: 0.5232\n",
            "Epoch 69/100\n",
            "2000/2000 [==============================] - 0s 141us/step - loss: 0.1928 - f1: 0.9183 - val_loss: 0.1931 - val_f1: 0.5232\n",
            "Epoch 70/100\n",
            "2000/2000 [==============================] - 0s 142us/step - loss: 0.1927 - f1: 0.9189 - val_loss: 0.1932 - val_f1: 0.5232\n",
            "Epoch 71/100\n",
            "2000/2000 [==============================] - 0s 139us/step - loss: 0.1927 - f1: 0.9154 - val_loss: 0.1932 - val_f1: 0.5232\n",
            "Epoch 72/100\n",
            "2000/2000 [==============================] - 0s 137us/step - loss: 0.1927 - f1: 0.9145 - val_loss: 0.1933 - val_f1: 0.5232\n",
            "Epoch 73/100\n",
            "2000/2000 [==============================] - 0s 133us/step - loss: 0.1927 - f1: 0.9185 - val_loss: 0.1931 - val_f1: 0.5232\n",
            "Epoch 74/100\n",
            "2000/2000 [==============================] - 0s 137us/step - loss: 0.1927 - f1: 0.9143 - val_loss: 0.1930 - val_f1: 0.5232\n",
            "Epoch 75/100\n",
            "2000/2000 [==============================] - 0s 143us/step - loss: 0.1927 - f1: 0.9193 - val_loss: 0.1932 - val_f1: 0.5232\n",
            "Epoch 76/100\n",
            "2000/2000 [==============================] - 0s 136us/step - loss: 0.1927 - f1: 0.9160 - val_loss: 0.1929 - val_f1: 0.5232\n",
            "Epoch 77/100\n",
            "2000/2000 [==============================] - 0s 134us/step - loss: 0.1927 - f1: 0.9162 - val_loss: 0.1932 - val_f1: 0.5232\n",
            "Epoch 78/100\n",
            "2000/2000 [==============================] - 0s 154us/step - loss: 0.1927 - f1: 0.9152 - val_loss: 0.1934 - val_f1: 0.5232\n",
            "Epoch 79/100\n",
            "2000/2000 [==============================] - 0s 143us/step - loss: 0.1927 - f1: 0.9154 - val_loss: 0.1930 - val_f1: 0.5232\n",
            "Epoch 80/100\n",
            "2000/2000 [==============================] - 0s 135us/step - loss: 0.1927 - f1: 0.9145 - val_loss: 0.1932 - val_f1: 0.5232\n",
            "Epoch 81/100\n",
            "2000/2000 [==============================] - 0s 142us/step - loss: 0.1926 - f1: 0.9170 - val_loss: 0.1931 - val_f1: 0.5232\n",
            "Epoch 82/100\n",
            "2000/2000 [==============================] - 0s 145us/step - loss: 0.1927 - f1: 0.9147 - val_loss: 0.1931 - val_f1: 0.5232\n",
            "Epoch 83/100\n",
            "2000/2000 [==============================] - 0s 134us/step - loss: 0.1926 - f1: 0.9159 - val_loss: 0.1932 - val_f1: 0.5232\n",
            "Epoch 84/100\n",
            "2000/2000 [==============================] - 0s 138us/step - loss: 0.1927 - f1: 0.9158 - val_loss: 0.1931 - val_f1: 0.5232\n",
            "Epoch 85/100\n",
            "2000/2000 [==============================] - 0s 139us/step - loss: 0.1927 - f1: 0.9147 - val_loss: 0.1931 - val_f1: 0.5232\n",
            "Epoch 86/100\n",
            "2000/2000 [==============================] - 0s 136us/step - loss: 0.1927 - f1: 0.9164 - val_loss: 0.1932 - val_f1: 0.5232\n",
            "Epoch 87/100\n",
            "2000/2000 [==============================] - 0s 139us/step - loss: 0.1926 - f1: 0.9148 - val_loss: 0.1933 - val_f1: 0.5232\n",
            "Epoch 88/100\n",
            "2000/2000 [==============================] - 0s 143us/step - loss: 0.1926 - f1: 0.9133 - val_loss: 0.1931 - val_f1: 0.5232\n",
            "Epoch 89/100\n",
            "2000/2000 [==============================] - 0s 140us/step - loss: 0.1926 - f1: 0.9178 - val_loss: 0.1934 - val_f1: 0.5232\n",
            "Epoch 90/100\n",
            "2000/2000 [==============================] - 0s 134us/step - loss: 0.1927 - f1: 0.9176 - val_loss: 0.1932 - val_f1: 0.5232\n",
            "Epoch 91/100\n",
            "2000/2000 [==============================] - 0s 133us/step - loss: 0.1927 - f1: 0.9140 - val_loss: 0.1933 - val_f1: 0.5232\n",
            "Epoch 92/100\n",
            "2000/2000 [==============================] - 0s 143us/step - loss: 0.1926 - f1: 0.9160 - val_loss: 0.1931 - val_f1: 0.5232\n",
            "Epoch 93/100\n",
            "2000/2000 [==============================] - 0s 139us/step - loss: 0.1927 - f1: 0.9151 - val_loss: 0.1933 - val_f1: 0.5232\n",
            "Epoch 94/100\n",
            "2000/2000 [==============================] - 0s 133us/step - loss: 0.1927 - f1: 0.9137 - val_loss: 0.1931 - val_f1: 0.5232\n",
            "Epoch 95/100\n",
            "2000/2000 [==============================] - 0s 135us/step - loss: 0.1927 - f1: 0.9172 - val_loss: 0.1932 - val_f1: 0.5232\n",
            "Epoch 96/100\n",
            "2000/2000 [==============================] - 0s 149us/step - loss: 0.1927 - f1: 0.9139 - val_loss: 0.1931 - val_f1: 0.5232\n",
            "Epoch 97/100\n",
            "2000/2000 [==============================] - 0s 133us/step - loss: 0.1926 - f1: 0.9160 - val_loss: 0.1932 - val_f1: 0.5232\n",
            "Epoch 98/100\n",
            "2000/2000 [==============================] - 0s 143us/step - loss: 0.1926 - f1: 0.9174 - val_loss: 0.1931 - val_f1: 0.5232\n",
            "Epoch 99/100\n",
            "2000/2000 [==============================] - 0s 143us/step - loss: 0.1926 - f1: 0.9142 - val_loss: 0.1931 - val_f1: 0.5232\n",
            "Epoch 100/100\n",
            "2000/2000 [==============================] - 0s 145us/step - loss: 0.1926 - f1: 0.9193 - val_loss: 0.1931 - val_f1: 0.5232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7ff55dea7f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obiXfa0L63TK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBh_AIxr6_Xq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6BcVvkB7A5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}