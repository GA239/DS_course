{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, GridSearchCV, cross_val_score, StratifiedShuffleSplit\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from functools import partial\n",
    "import itertools\n",
    "from sklift.models import ClassTransformation\n",
    "import lightgbm as lgbm\n",
    "import ipywidgets as widgets\n",
    "import inspect\n",
    "from datetime import timedelta\n",
    "from sklearn import preprocessing\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# create logger\n",
    "logger = logging.getLogger('lg')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# create console handler and set level to debug\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "\n",
    "# create formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# add formatter to ch\n",
    "ch.setFormatter(formatter)\n",
    "\n",
    "# add ch to logger\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-29 18:27:48,052 - lg - INFO - info message\n"
     ]
    }
   ],
   "source": [
    "logger.info('info message')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_TRANSACTION_TEMPLATE = 'base_transaction'\n",
    "FAVORITES_TEMPLATE = 'favorites'\n",
    "STEPS_MAPPING = {\n",
    "    'BASE': (False, 'base_features.csv'),\n",
    "    'BASE_TRANSACTION': (False, BASE_TRANSACTION_TEMPLATE),\n",
    "    'FAVORITES': (False, FAVORITES_TEMPLATE),\n",
    "    'POPULARITY': (True, 'popularity'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_file_name(prefix, offset):\n",
    "    return '{}_{}.csv'.format(prefix, str(offset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features_from_files(offsets):\n",
    "    features = pd.read_csv(STEPS_MAPPING['BASE'][1], index_col='client_id')\n",
    "    \n",
    "    base_trans_array = []\n",
    "    for offset in offsets:\n",
    "        offset = offset or ''\n",
    "        base_trans_array.append(pd.read_csv(generate_file_name(STEPS_MAPPING['BASE_TRANSACTION'][1], offset), \n",
    "                                 index_col='client_id'))\n",
    "    \n",
    "    for df in base_trans_array:\n",
    "        features = features.merge(df, left_index=True, right_index=True)\n",
    "        del df\n",
    "\n",
    "    gc.collect()\n",
    "    favorites_array = []\n",
    "    for offset in offsets:\n",
    "        offset = offset or ''\n",
    "        favorites_array.append(pd.read_csv(generate_file_name(STEPS_MAPPING['FAVORITES'][1], offset), \n",
    "                                           index_col='client_id'))\n",
    "    \n",
    "    for df in favorites_array:\n",
    "        features = features.merge(df, left_index=True, right_index=True)\n",
    "        del df\n",
    "    gc.collect()\n",
    "\n",
    "    popularity_array = []\n",
    "    for offset in offsets:\n",
    "        offset = offset or ''\n",
    "        popularity_array.append(pd.read_csv(generate_file_name(STEPS_MAPPING['POPULARITY'][1], offset), \n",
    "                                           index_col='client_id'))\n",
    "    \n",
    "    for df in popularity_array:\n",
    "        features = features.merge(df, left_index=True, right_index=True)\n",
    "        del df\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uplift_score(prediction, treatment, target, rate=0.3):\n",
    "    \"\"\"\n",
    "    Подсчет Uplift Score\n",
    "    \"\"\"\n",
    "    order = np.argsort(-prediction)\n",
    "\n",
    "    treatment_n = int((treatment == 1).sum() * rate)\n",
    "    treatment_p = target[order][treatment[order] == 1][:treatment_n].mean()\n",
    "\n",
    "    control_n = int((treatment == 0).sum() * rate)\n",
    "    control_p = target[order][treatment[order] == 0][:control_n].mean()\n",
    "\n",
    "    score = treatment_p - control_p\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_train_test(features, df_train, df_test):\n",
    "    return features.loc[df_train.index, :], features.loc[df_test.index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def balance_learn(X_learn, y_learn):\n",
    "    _, treatment_counts = np.unique(y_learn.treatment_flg, return_counts=True)\n",
    "    logger.info(\"{}, {}, {}\".format(X_learn.shape, y_learn.shape, treatment_counts[0] - treatment_counts[1]))\n",
    "    \n",
    "    treat_learn = y_learn.treatment_flg\n",
    "    vc = treat_learn.value_counts()\n",
    "    treat_learn = pd.concat([treat_learn[treat_learn == i].sample(vc.min()) for i in vc.index])\n",
    "\n",
    "    X_learn = X_learn.loc[treat_learn.index, :]\n",
    "    y_learn = y_learn.loc[treat_learn.index, :]\n",
    "    \n",
    "    _, treatment_counts = np.unique(y_learn.treatment_flg, return_counts=True)\n",
    "    logger.info(\"{}, {}, {}\".format(X_learn.shape, y_learn.shape, treatment_counts[0] - treatment_counts[1]))\n",
    "    return X_learn, y_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uplift_score_func(y_true, y_pred, **kwargs):\n",
    "    return uplift_score(y_pred, treatment=y_true.treatment_flg, target=y_true.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyClassTransformation(ClassTransformation):\n",
    "    def fit(self, X, y, estimator_fit_params=None):\n",
    "        return  super().fit(X, y=y.target, treatment=y.treatment_flg, estimator_fit_params=estimator_fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_transactions_and_products(products, transactions):\n",
    "    columns = ['brand_id', 'vendor_id', 'segment_id', 'product_id']\n",
    "    transactions_with_products = transactions.merge(products, left_on='product_id', right_index=True)\n",
    "    logger.info('transactions_with_products')\n",
    "    for col in columns:\n",
    "        fg = transactions_with_products.drop_duplicates(subset=['client_id', col]) \\\n",
    "                                       .groupby([col]).size().sort_values(ascending=False)\n",
    "        fg.name = 'popularity_{}'.format(col)\n",
    "        \n",
    "        if col == 'product_id':\n",
    "            products = products.merge(fg, left_index=True, right_index=True)\n",
    "        else:\n",
    "            products = products.join(fg, on=col)\n",
    "        logger.info('popularity {}'.format(col))\n",
    "    new_columns = ['popularity_{}'.format(col) for col in columns]\n",
    "    transactions_with_products = transactions_with_products.merge(products[new_columns], left_on='product_id', right_index=True)\n",
    "    return transactions_with_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_transactions(df_purchases, offset=None):\n",
    "    if not offset:\n",
    "        return df_purchases\n",
    "\n",
    "    last_date = df_purchases.date.max()    \n",
    "    sub_df_purchases = df_purchases[df_purchases.date > last_date-timedelta(days=offset)]\n",
    "    logger.info(\"sub_df_purchases shape : {}\".format(sub_df_purchases.shape))\n",
    "    return sub_df_purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_products = pd.read_csv('data/products.csv', index_col='product_id')\n",
    "# logger.info(df_products.shape)\n",
    "\n",
    "# # df_purchases = pd.read_csv('data/purchases.csv', index_col='transaction_id', parse_dates=['transaction_datetime'], nrows=100000)\n",
    "# df_purchases = pd.read_csv('data/purchases.csv', index_col='transaction_id', parse_dates=['transaction_datetime'])\n",
    "# df_purchases['date'] = df_purchases['transaction_datetime'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_products_features(trans):\n",
    "    columns = ['brand_id', 'vendor_id', 'segment_id', 'product_id']\n",
    "    columns2 = ['popularity_{}'.format(col) for col in columns]\n",
    "    total_pop = trans.groupby('client_id')[columns2].sum()\n",
    "    logger.info(total_pop.columns[0])\n",
    "    yield total_pop\n",
    "    \n",
    "    avg_trans_pop = trans.groupby(['client_id', 'transaction_id'])[columns2].sum().groupby(['client_id'])[columns2].mean()\n",
    "    avg_trans_pop.columns = ['avg_trans_{}'.format(c) for c in avg_trans_pop.columns]\n",
    "    logger.info(avg_trans_pop.columns[0])\n",
    "    yield avg_trans_pop\n",
    "\n",
    "    total_unique = trans.groupby(['client_id'])[columns].nunique()\n",
    "    total_unique.columns = ['total_unique_{}'.format(c) for c in total_unique.columns]\n",
    "    logger.info(total_unique.columns[0])\n",
    "    yield total_unique\n",
    "\n",
    "    avg_trans_unique = trans.groupby(['client_id', 'transaction_id'])[columns].nunique().groupby(['client_id'])[columns].mean()\n",
    "    avg_trans_unique.columns = ['avg_trans_unique_{}'.format(c) for c in avg_trans_unique.columns]\n",
    "    logger.info(avg_trans_unique.columns[0])\n",
    "    yield avg_trans_unique\n",
    "    \n",
    "    result = []\n",
    "    for c in columns[:-1]:\n",
    "        fc = trans.groupby(['client_id', c])['product_id'].nunique().groupby(['client_id']).mean()\n",
    "        fc.name = 'avg_nunique_prod_in_{}'.format(c)\n",
    "        result.append(fc)\n",
    "    avg_nunique_prod = pd.concat(result, axis=1, sort=False)\n",
    "    logger.info(avg_nunique_prod.columns[0])\n",
    "    yield avg_nunique_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop_features(offset):\n",
    "    offset = offset or ''\n",
    "    final = None\n",
    "    for df in get_products_features(df_purchases):    \n",
    "        final = final.merge(df, left_index=True, right_index=True) if final is not None else df\n",
    "    final.index.name = 'client_id'\n",
    "    if STEPS_MAPPING['POPULARITY'][0]:\n",
    "        final.to_csv(generate_file_name(STEPS_MAPPING['POPULARITY'][1], offset))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def base_features(clean=True):\n",
    "    df_features = pd.read_csv('data/clients.csv', index_col='client_id', parse_dates=['first_issue_date','first_redeem_date'])\n",
    "    df_features['gender'] = LabelEncoder().fit_transform(df_features.gender)\n",
    "    df_features['first_issue_time'] = pd.to_datetime(df_features['first_issue_date']).astype(int) / 10 ** 9\n",
    "    df_features['first_redeem_time'] = pd.to_datetime(df_features['first_redeem_date']).astype(int) / 10 ** 9\n",
    "    df_features['issue_redeem_delay'] = df_features['first_redeem_time'] - df_features['first_issue_time']\n",
    "    df_features = df_features.drop(['first_issue_date', 'first_redeem_date'], axis=1)\n",
    "    if STEPS_MAPPING['BASE'][0]:\n",
    "        df_features.to_csv(STEPS_MAPPING['BASE'][1])\n",
    "    \n",
    "    if clean:\n",
    "        del df_features\n",
    "        gc.collect()\n",
    "        return\n",
    "\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transactions_features(transactions, offset=None, clean=True):\n",
    "    offset = offset or ''\n",
    "    last_cols = [\n",
    "        'regular_points_received', \n",
    "        'express_points_received',\n",
    "        'regular_points_spent',\n",
    "        'express_points_spent',\n",
    "        'purchase_sum'\n",
    "    ]\n",
    "\n",
    "    logger.info(\"Create history\")\n",
    "    history = transactions.groupby(['client_id', 'transaction_id'])[last_cols].last()\n",
    "    \n",
    "    logger.info(\"Create _features\")\n",
    "    _features = [\n",
    "        (history.groupby('client_id')['purchase_sum'].count(), ['total_trans_count']), \n",
    "        (history.groupby('client_id').sum(), last_cols)\n",
    "    ]\n",
    "    \n",
    "    _features = list(zip(*_features))\n",
    "    transactions_features =  pd.concat(_features[0], axis = 1)\n",
    "    transactions_features.columns = list(itertools.chain.from_iterable(_features[1]))\n",
    "    transactions_features.columns = ['days_{}_'.format(str(offset)) + c for c in transactions_features.columns]\n",
    "    if STEPS_MAPPING['BASE_TRANSACTION'][0]:\n",
    "        transactions_features.to_csv(generate_file_name(STEPS_MAPPING['BASE_TRANSACTION'][1], offset))\n",
    "    \n",
    "    if clean:\n",
    "        del transactions_features\n",
    "        gc.collect()\n",
    "        return\n",
    "\n",
    "    \n",
    "    return transactions_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def favorite_products_features(merged_transactions, offset=None, clean=True):\n",
    "\n",
    "    offset = offset or ''\n",
    "    # вычисляем любимый продукт/категорию/сегмент для каждого юзера.\n",
    "    cols = ['product_id', 'brand_id', 'vendor_id', 'segment_id']\n",
    "    result = []\n",
    "    for c in cols:\n",
    "        logger.info(\"favorite {}\".format(c))\n",
    "        result.append(\n",
    "            merged_transactions.groupby(['client_id', c]).size().reset_index(name='counts').groupby(['client_id']).max()[c]\n",
    "        )\n",
    "\n",
    "    favorites = pd.concat(result, axis=1, sort=False)\n",
    "    favorites.columns = [str(offset) + '_faivorite_' + c for c in cols]\n",
    "    favorites.index.name = 'client_id'\n",
    "\n",
    "    for col in favorites.columns:\n",
    "        logger.info('LabelEncoder for {}'.format(col))\n",
    "        favorites[col] = LabelEncoder().fit_transform(favorites[col].astype(str))    \n",
    "\n",
    "    if STEPS_MAPPING['FAVORITES'][0]:\n",
    "        favorites.to_csv(generate_file_name(STEPS_MAPPING['FAVORITES'][1], offset))\n",
    "\n",
    "    if clean:\n",
    "        del favorites\n",
    "        gc.collect()\n",
    "        return        \n",
    "        \n",
    "    return favorites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_the_first_part_of_features(offset, df_products, df_purchases):\n",
    "    sb_df_purchases = get_transactions(df_purchases, offset=offset)\n",
    "    transactions_features(sb_df_purchases, offset=offset)\n",
    "    sb_df_purchases = merge_transactions_and_products(df_products, sb_df_purchases)\n",
    "    favorite_products_features(merged_transactions=sb_df_purchases, offset=offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base_features(df_clients);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# offets = [None]\n",
    "# for offst in offets:\n",
    "#     logger.info('{} offst = {}'.format('--'*30, offst))\n",
    "#     generate_the_first_part_of_features(offst, df_products, df_purchases);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# offset = 14\n",
    "# df_purchases = merge_transactions_and_products(df_products, get_transactions(df_purchases, offset=offset))\n",
    "# tpf = pop_features(offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "offets = [14, 30, None]\n",
    "features = get_features_from_files(offets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>first_issue_time</th>\n",
       "      <th>first_redeem_time</th>\n",
       "      <th>issue_redeem_delay</th>\n",
       "      <th>days_14_total_trans_count</th>\n",
       "      <th>days_14_regular_points_received</th>\n",
       "      <th>days_14_express_points_received</th>\n",
       "      <th>days_14_regular_points_spent</th>\n",
       "      <th>days_14_express_points_spent</th>\n",
       "      <th>...</th>\n",
       "      <th>total_unique_vendor_id</th>\n",
       "      <th>total_unique_segment_id</th>\n",
       "      <th>total_unique_product_id</th>\n",
       "      <th>avg_trans_unique_brand_id</th>\n",
       "      <th>avg_trans_unique_vendor_id</th>\n",
       "      <th>avg_trans_unique_segment_id</th>\n",
       "      <th>avg_trans_unique_product_id</th>\n",
       "      <th>avg_nunique_prod_in_brand_id</th>\n",
       "      <th>avg_nunique_prod_in_vendor_id</th>\n",
       "      <th>avg_nunique_prod_in_segment_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000012768d</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>1.501948e+09</td>\n",
       "      <td>1.515094e+09</td>\n",
       "      <td>1.314656e+07</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>46</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.586207</td>\n",
       "      <td>1.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000036f903</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>1.491832e+09</td>\n",
       "      <td>1.492951e+09</td>\n",
       "      <td>1.118613e+06</td>\n",
       "      <td>3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>96</td>\n",
       "      <td>3.937500</td>\n",
       "      <td>3.968750</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>5.062500</td>\n",
       "      <td>1.803922</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>2.268293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000048b7a6</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1.544881e+09</td>\n",
       "      <td>-9.223372e+09</td>\n",
       "      <td>-1.076825e+10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.904762</td>\n",
       "      <td>2.095238</td>\n",
       "      <td>2.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000073194a</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1.495544e+09</td>\n",
       "      <td>1.511522e+09</td>\n",
       "      <td>1.597811e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>68</td>\n",
       "      <td>3.823529</td>\n",
       "      <td>3.941176</td>\n",
       "      <td>3.294118</td>\n",
       "      <td>4.823529</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>1.619048</td>\n",
       "      <td>2.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00007f9014</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1.503409e+09</td>\n",
       "      <td>1.550258e+09</td>\n",
       "      <td>4.684946e+07</td>\n",
       "      <td>2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>38</td>\n",
       "      <td>71</td>\n",
       "      <td>3.448276</td>\n",
       "      <td>3.413793</td>\n",
       "      <td>3.448276</td>\n",
       "      <td>3.827586</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>1.651163</td>\n",
       "      <td>1.763158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  gender  first_issue_time  first_redeem_time  \\\n",
       "client_id                                                      \n",
       "000012768d   45       2      1.501948e+09       1.515094e+09   \n",
       "000036f903   72       0      1.491832e+09       1.492951e+09   \n",
       "000048b7a6   68       0      1.544881e+09      -9.223372e+09   \n",
       "000073194a   60       0      1.495544e+09       1.511522e+09   \n",
       "00007f9014   45       0      1.503409e+09       1.550258e+09   \n",
       "\n",
       "            issue_redeem_delay  days_14_total_trans_count  \\\n",
       "client_id                                                   \n",
       "000012768d        1.314656e+07                          2   \n",
       "000036f903        1.118613e+06                          3   \n",
       "000048b7a6       -1.076825e+10                          1   \n",
       "000073194a        1.597811e+07                          1   \n",
       "00007f9014        4.684946e+07                          2   \n",
       "\n",
       "            days_14_regular_points_received  days_14_express_points_received  \\\n",
       "client_id                                                                      \n",
       "000012768d                             10.0                              0.0   \n",
       "000036f903                              4.1                              0.0   \n",
       "000048b7a6                              1.2                              0.0   \n",
       "000073194a                              1.3                              0.0   \n",
       "00007f9014                              3.3                              0.0   \n",
       "\n",
       "            days_14_regular_points_spent  days_14_express_points_spent  ...  \\\n",
       "client_id                                                               ...   \n",
       "000012768d                           0.0                           0.0  ...   \n",
       "000036f903                           0.0                           0.0  ...   \n",
       "000048b7a6                           0.0                           0.0  ...   \n",
       "000073194a                           0.0                           0.0  ...   \n",
       "00007f9014                           0.0                           0.0  ...   \n",
       "\n",
       "            total_unique_vendor_id  total_unique_segment_id  \\\n",
       "client_id                                                     \n",
       "000012768d                      29                       23   \n",
       "000036f903                      44                       41   \n",
       "000048b7a6                      21                       16   \n",
       "000073194a                      42                       27   \n",
       "00007f9014                      43                       38   \n",
       "\n",
       "            total_unique_product_id  avg_trans_unique_brand_id  \\\n",
       "client_id                                                        \n",
       "000012768d                       46                  10.500000   \n",
       "000036f903                       96                   3.937500   \n",
       "000048b7a6                       44                   4.000000   \n",
       "000073194a                       68                   3.823529   \n",
       "00007f9014                       71                   3.448276   \n",
       "\n",
       "            avg_trans_unique_vendor_id  avg_trans_unique_segment_id  \\\n",
       "client_id                                                             \n",
       "000012768d                   11.000000                    11.000000   \n",
       "000036f903                    3.968750                     4.250000   \n",
       "000048b7a6                    4.375000                     3.500000   \n",
       "000073194a                    3.941176                     3.294118   \n",
       "00007f9014                    3.413793                     3.448276   \n",
       "\n",
       "            avg_trans_unique_product_id  avg_nunique_prod_in_brand_id  \\\n",
       "client_id                                                               \n",
       "000012768d                    13.000000                      1.500000   \n",
       "000036f903                     5.062500                      1.803922   \n",
       "000048b7a6                     7.000000                      1.904762   \n",
       "000073194a                     4.823529                      1.571429   \n",
       "00007f9014                     3.827586                      1.380000   \n",
       "\n",
       "            avg_nunique_prod_in_vendor_id  avg_nunique_prod_in_segment_id  \n",
       "client_id                                                                  \n",
       "000012768d                       1.586207                        1.956522  \n",
       "000036f903                       2.181818                        2.268293  \n",
       "000048b7a6                       2.095238                        2.625000  \n",
       "000073194a                       1.619048                        2.370370  \n",
       "00007f9014                       1.651163                        1.763158  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346831, 92)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-29 18:28:01,338 - lg - INFO - (200039, 2)\n",
      "2020-01-29 18:28:01,483 - lg - INFO - (200123, 0)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/uplift_train.csv', index_col='client_id')\n",
    "logger.info(df_train.shape)\n",
    "\n",
    "df_test = pd.read_csv('data/uplift_test.csv', index_col='client_id')\n",
    "logger.info(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test = get_train_test(features, df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>first_issue_time</th>\n",
       "      <th>first_redeem_time</th>\n",
       "      <th>issue_redeem_delay</th>\n",
       "      <th>days_14_total_trans_count</th>\n",
       "      <th>days_14_regular_points_received</th>\n",
       "      <th>days_14_express_points_received</th>\n",
       "      <th>days_14_regular_points_spent</th>\n",
       "      <th>days_14_express_points_spent</th>\n",
       "      <th>...</th>\n",
       "      <th>total_unique_vendor_id</th>\n",
       "      <th>total_unique_segment_id</th>\n",
       "      <th>total_unique_product_id</th>\n",
       "      <th>avg_trans_unique_brand_id</th>\n",
       "      <th>avg_trans_unique_vendor_id</th>\n",
       "      <th>avg_trans_unique_segment_id</th>\n",
       "      <th>avg_trans_unique_product_id</th>\n",
       "      <th>avg_nunique_prod_in_brand_id</th>\n",
       "      <th>avg_nunique_prod_in_vendor_id</th>\n",
       "      <th>avg_nunique_prod_in_segment_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000012768d</th>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.501948e+09</td>\n",
       "      <td>1.515094e+09</td>\n",
       "      <td>13146559.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.586207</td>\n",
       "      <td>1.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000036f903</th>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.491832e+09</td>\n",
       "      <td>1.492951e+09</td>\n",
       "      <td>1118613.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3.937500</td>\n",
       "      <td>3.968750</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>5.062500</td>\n",
       "      <td>1.803922</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>2.268293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00010925a5</th>\n",
       "      <td>83.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.532449e+09</td>\n",
       "      <td>1.536942e+09</td>\n",
       "      <td>4492280.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.055556</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.037037</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>1.774194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001f552b0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.498850e+09</td>\n",
       "      <td>1.535461e+09</td>\n",
       "      <td>36610747.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>5.733333</td>\n",
       "      <td>1.630435</td>\n",
       "      <td>1.880952</td>\n",
       "      <td>1.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00020e7b18</th>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.511783e+09</td>\n",
       "      <td>1.515607e+09</td>\n",
       "      <td>3823700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>10.111111</td>\n",
       "      <td>10.388889</td>\n",
       "      <td>15.111111</td>\n",
       "      <td>1.941860</td>\n",
       "      <td>2.536232</td>\n",
       "      <td>3.886364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  gender  first_issue_time  first_redeem_time  \\\n",
       "client_id                                                       \n",
       "000012768d  45.0     2.0      1.501948e+09       1.515094e+09   \n",
       "000036f903  72.0     0.0      1.491832e+09       1.492951e+09   \n",
       "00010925a5  83.0     2.0      1.532449e+09       1.536942e+09   \n",
       "0001f552b0  33.0     0.0      1.498850e+09       1.535461e+09   \n",
       "00020e7b18  73.0     2.0      1.511783e+09       1.515607e+09   \n",
       "\n",
       "            issue_redeem_delay  days_14_total_trans_count  \\\n",
       "client_id                                                   \n",
       "000012768d          13146559.0                        2.0   \n",
       "000036f903           1118613.0                        3.0   \n",
       "00010925a5           4492280.0                        4.0   \n",
       "0001f552b0          36610747.0                        4.0   \n",
       "00020e7b18           3823700.0                        2.0   \n",
       "\n",
       "            days_14_regular_points_received  days_14_express_points_received  \\\n",
       "client_id                                                                      \n",
       "000012768d                             10.0                              0.0   \n",
       "000036f903                              4.1                              0.0   \n",
       "00010925a5                              5.8                              0.0   \n",
       "0001f552b0                             44.7                              0.0   \n",
       "00020e7b18                             15.6                              0.0   \n",
       "\n",
       "            days_14_regular_points_spent  days_14_express_points_spent  ...  \\\n",
       "client_id                                                               ...   \n",
       "000012768d                           0.0                           0.0  ...   \n",
       "000036f903                           0.0                           0.0  ...   \n",
       "00010925a5                           0.0                           0.0  ...   \n",
       "0001f552b0                           0.0                           0.0  ...   \n",
       "00020e7b18                         -58.0                         -10.0  ...   \n",
       "\n",
       "            total_unique_vendor_id  total_unique_segment_id  \\\n",
       "client_id                                                     \n",
       "000012768d                    29.0                     23.0   \n",
       "000036f903                    44.0                     41.0   \n",
       "00010925a5                    24.0                     31.0   \n",
       "0001f552b0                    42.0                     40.0   \n",
       "00020e7b18                    69.0                     44.0   \n",
       "\n",
       "            total_unique_product_id  avg_trans_unique_brand_id  \\\n",
       "client_id                                                        \n",
       "000012768d                     46.0                  10.500000   \n",
       "000036f903                     96.0                   3.937500   \n",
       "00010925a5                     58.0                   3.055556   \n",
       "0001f552b0                     79.0                   4.466667   \n",
       "00020e7b18                    175.0                  11.500000   \n",
       "\n",
       "            avg_trans_unique_vendor_id  avg_trans_unique_segment_id  \\\n",
       "client_id                                                             \n",
       "000012768d                   11.000000                    11.000000   \n",
       "000036f903                    3.968750                     4.250000   \n",
       "00010925a5                    3.222222                     3.833333   \n",
       "0001f552b0                    4.533333                     4.533333   \n",
       "00020e7b18                   10.111111                    10.388889   \n",
       "\n",
       "            avg_trans_unique_product_id  avg_nunique_prod_in_brand_id  \\\n",
       "client_id                                                               \n",
       "000012768d                    13.000000                      1.500000   \n",
       "000036f903                     5.062500                      1.803922   \n",
       "00010925a5                     4.333333                      2.037037   \n",
       "0001f552b0                     5.733333                      1.630435   \n",
       "00020e7b18                    15.111111                      1.941860   \n",
       "\n",
       "            avg_nunique_prod_in_vendor_id  avg_nunique_prod_in_segment_id  \n",
       "client_id                                                                  \n",
       "000012768d                       1.586207                        1.956522  \n",
       "000036f903                       2.181818                        2.268293  \n",
       "00010925a5                       2.416667                        1.774194  \n",
       "0001f552b0                       1.880952                        1.925000  \n",
       "00020e7b18                       2.536232                        3.886364  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices_learn, indices_valid = train_test_split(x_train.index, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_learn = x_train.loc[indices_learn, :]\n",
    "y_learn = df_train.loc[indices_learn, :]\n",
    "\n",
    "X_val = x_train.loc[indices_valid, :]\n",
    "y_val = df_train.loc[indices_valid, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'learning_rate':0.01,'max_depth':4,'num_leaves':20,\n",
    "             'min_data_in_leaf':3, 'application':'binary', 'subsample':0.8, 'colsample_bytree': 0.8,\n",
    "             'reg_alpha':0.01,'data_random_seed':42,'metric':'binary_logloss',\n",
    "             'max_bin':416,'bagging_freq':3,'reg_lambda':0.01             \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's binary_logloss: 0.600488 + 0.000389785\n",
      "[100]\tcv_agg's binary_logloss: 0.573186 + 0.00066633\n",
      "[150]\tcv_agg's binary_logloss: 0.560759 + 0.000884604\n",
      "[200]\tcv_agg's binary_logloss: 0.554753 + 0.000996158\n",
      "[250]\tcv_agg's binary_logloss: 0.55151 + 0.00111232\n",
      "[300]\tcv_agg's binary_logloss: 0.549585 + 0.00108661\n",
      "[350]\tcv_agg's binary_logloss: 0.548443 + 0.00101545\n",
      "[400]\tcv_agg's binary_logloss: 0.547586 + 0.00103483\n",
      "[450]\tcv_agg's binary_logloss: 0.546978 + 0.00111082\n",
      "[500]\tcv_agg's binary_logloss: 0.546359 + 0.00111044\n",
      "[550]\tcv_agg's binary_logloss: 0.545984 + 0.00112738\n",
      "[600]\tcv_agg's binary_logloss: 0.545704 + 0.00111188\n",
      "[650]\tcv_agg's binary_logloss: 0.545479 + 0.00108747\n",
      "[700]\tcv_agg's binary_logloss: 0.54528 + 0.00107776\n",
      "[750]\tcv_agg's binary_logloss: 0.545159 + 0.00103656\n"
     ]
    }
   ],
   "source": [
    "matrix = lgbm.Dataset(X_learn, label=y_learn.target)\n",
    "cv_result = lgbm.cv(params, matrix, num_boost_round=2000,nfold=5, stratified=True, \n",
    "                    shuffle=True, early_stopping_rounds=50, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cv_result['binary_logloss-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params['n_estimators'] = len(cv_result['binary_logloss-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "parameters = {\n",
    "    'classifier__estimator__max_depth': [3, 4, 5],\n",
    "    'classifier__estimator__num_leaves': list(range(20, 100, 15)),\n",
    "    'classifier__estimator__min_child_samples': list(range(20, 100, 15)),\n",
    "    'classifier__estimator__class_weight': ['balanced', None]\n",
    "\n",
    "}\n",
    "modelcv = GridSearchCV(\n",
    "    Pipeline(steps=[\n",
    "        ('classifier', MyClassTransformation(lgbm.LGBMClassifier(**params)))\n",
    "    ]),\n",
    "    parameters,\n",
    "    scoring=make_scorer(uplift_score_func), \n",
    "    cv=ShuffleSplit(n_splits=4, test_size=0.3, random_state=12), \n",
    "    verbose=3, n_jobs=-1\n",
    ")\n",
    "modelcv.fit(X_learn, y_learn);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = modelcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Validation score:', uplift_score(final_model.predict(X_val), treatment=y_val.treatment_flg, target=y_val.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(\n",
    "    final_model, x_train, df_train,\n",
    "    cv=ShuffleSplit(n_splits=10, test_size=0.3), \n",
    "    scoring=make_scorer(uplift_score_func)\n",
    ")\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### вычислим доверительный интервал оценки прогноза, чтобы по Public отсеживать overfit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores), st.sem(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.t.interval(0.95, len(scores)-1, loc=np.mean(scores), scale=st.sem(scores)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка предсказаний для тестовых клиентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, df_train = balance_learn(x_train, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.fit(x_train, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "upl_sc = final_model.predict(x_test)\n",
    "pd.DataFrame({'client_id':x_test.index.values,'uplift': upl_sc}).to_csv('final_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({\n",
    "    'feature_score': final_model.steps[0][1].estimator.feature_importances_\n",
    "}, index=x_train.columns).sort_values('feature_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = fi.tail(15).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Local PySpark (Python-3.5 / Spark-2.3.0 )",
   "language": "python",
   "name": "py3spark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
